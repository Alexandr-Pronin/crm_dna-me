<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session d4a8d810-27bd-441d-b67d-b80d22e4b841 (2026-01-22 11:28Z) -->

# Rate limit middleware implementation (2026-01-22 11:28Z)

_**User (2026-01-22 09:18Z)**_

Implement the following to-dos from the plan (the plan is attached for your reference). Do NOT edit the plan file itself.

You have been assigned the following 1 to-do(s) with IDs: rate-limit

1. [rate-limit] Erstelle src/api/middleware/rateLimit.ts

These to-dos have already been created. Do not create them again. Mark them as in_progress as you work, starting with the first one. Don't stop until you have completed all the assigned to-dos.

---

_**Agent (model claude-4.5-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
Der Benutzer möchte, dass ich die Rate-Limiting Middleware implementiere. Laut dem Plan:

- `src/api/middleware/rateLimit.ts` - Per-source rate limiting

Ich sollte zuerst die bestehende Projektstruktur und den Code verstehen, um sicherzustellen, dass die Implementierung konsistent ist. Lass mich schauen:

1. Zuerst markiere ich den Task als in_progress
2. Dann schaue ich mir die bestehende Middleware-Struktur an
3. Implementiere die rateLimit Middleware
4. Markiere den Task als completed

Lass mich anfangen.</details></think>

---

Ich werde die Rate-Limiting Middleware implementieren. Zuerst schaue ich mir die bestehende Middleware-Struktur und die Projektkonventionen an.

---

<tool-use data-tool-type="task" data-tool-name="todo_write">
<details><summary>Tool use: **todo_write** • Todo List</summary>

- [-] Erstelle src/api/middleware/rateLimit.ts

</details>
</tool-use>

---

<tool-use data-tool-type="generic" data-tool-name="list_dir">
<details>
            <summary>Tool use: **list_dir** • Listed directory, 0 results</summary>
        
No results found
</details>
</tool-use>

---

<tool-use data-tool-type="generic" data-tool-name="list_dir">
<details>
            <summary>Tool use: **list_dir** • Listed directory, 0 results</summary>
        
No results found
</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Gut, es gibt bereits eine Middleware-Struktur. Lass mich die bestehenden Middleware-Dateien lesen, um den Stil und die Konventionen zu verstehen. Ich werde auch die Master-Prompt-Dokumentation lesen, um zu sehen, welche Anforderungen das Rate-Limiting haben sollte.</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: e:\dname\crm_dna-me\src\api\middleware\apiKey.ts</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: e:\dname\crm_dna-me\src\api\middleware\errorHandler.ts</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: e:\dname\crm_dna-me\docs\DNA_ME_CRM_CURSOR_MASTER_PROMPT_PART1.md</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Jetzt habe ich einen guten Überblick über:
1. Die bestehenden Middleware-Konventionen
2. Das Projekt verwendet Fastify
3. Der Master-Prompt erwähnt "Per-source rate limiting" in `src/api/middleware/rateLimit.ts`

Ich sollte auch die Config-Struktur anschauen, um zu verstehen, wie API-Keys konfiguriert werden und wie ich Rate-Limiting basierend auf API-Key-Quellen implementieren kann.

Lass mich mir die Config-Struktur ansehen und auch schauen, ob es bereits Redis-Verbindungen im Projekt gibt.</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: e:\dname\crm_dna-me\src\config\index.ts</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** • Searched codebase "Where is Redis configured and used for connections?" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `src/config/redis.ts` | L12-44 |
| `src/config/redis.ts` | L27-70 |
| `src/config/redis.ts` | L25 |
| `src/config/index.ts` | L6-68 |
| `src/index.ts` | L152-232 |
| `src/config/index.ts` | L85-137 |
| `src/index.ts` | L55 |
| `src/config/redis.ts` | L50-84 |
| `src/config/redis.ts` | L88-96 |
| `src/config/queues.ts` | L18-59 |
| `src/config/redis.ts` | L74-96 |
| `src/workers/index.ts` | L21-120 |
| `src/workers/routingWorker.ts` | L66 |
| `src/db/index.ts` | L50 |
| `src/index.ts` | L50-91 |

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Gut, ich habe jetzt alle Informationen, die ich brauche:

1. Die Config hat bereits `rateLimit.max` und `rateLimit.timeWindow` definiert
2. Redis ist über ioredis konfiguriert und es gibt eine `getRedisConnection()` Funktion
3. Die anderen Middleware-Dateien verwenden einen konsistenten Stil mit Fastify

Jetzt werde ich die Rate-Limiting Middleware implementieren. Sie sollte:
1. Per-Source Rate-Limiting basierend auf dem `apiKeySource` unterstützen
2. Redis für den Speicher verwenden (für verteilte Umgebungen)
3. Im gleichen Stil wie die anderen Middleware-Dateien geschrieben sein
4. Die Konfiguration aus `config.rateLimit` verwenden

Ich sollte auch die Errors-Struktur im Projekt ansehen.</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: e:\dname\crm_dna-me\src\errors\index.ts</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: e:\dname\crm_dna-me\src\config\redis.ts</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Perfekt! Ich habe jetzt alle Informationen:

1. Es gibt bereits ein `RateLimitError` in `src/errors/index.ts`
2. Redis ist konfiguriert mit `getRedisConnection()` in `src/config/redis.ts`
3. Die Konfiguration hat `config.rateLimit.max` und `config.rateLimit.timeWindow`
4. Die anderen Middleware-Dateien verwenden einen konsistenten Stil

Jetzt werde ich die Rate-Limiting Middleware erstellen, die:
1. Per-Source Rate-Limiting basierend auf `apiKeySource` unterstützt (wenn vorhanden)
2. Als Fallback IP-basiertes Rate-Limiting verwendet
3. Redis für den Speicher verwendet (Sliding Window Algorithmus)
4. Die bestehenden Fehlerklassen verwendet
5. Im gleichen Stil wie die anderen Middleware-Dateien geschrieben ist

Ich werde einen Sliding Window Log Algorithmus implementieren, der in Redis gespeichert wird.</details></think>

---

Jetzt habe ich alle nötigen Informationen. Ich erstelle die Rate-Limiting Middleware mit Redis-basiertem Per-Source Rate-Limiting:

---

<tool-use data-tool-type="write" data-tool-name="write">

<details><summary>Tool use: **write** • Edit file: e:\dname\crm_dna-me\src\api\middleware\rateLimit.ts</summary>

**Chunk 1**
Lines added: 323, lines removed: 1

```diff
@@ -1,1 +1,323 @@
- 
+ // =============================================================================
+ // src/api/middleware/rateLimit.ts
+ // Per-Source Rate Limiting Middleware with Redis Backend
+ // =============================================================================
+ 
+ import type { FastifyRequest, FastifyReply } from 'fastify';
+ import { getRedisConnection } from '../../config/redis.js';
+ import { config } from '../../config/index.js';
+ import { RateLimitError } from '../../errors/index.js';
+ 
+ // =============================================================================
+ // Types
+ // =============================================================================
+ 
+ interface RateLimitConfig {
+   /** Maximum requests allowed in the time window */
+   max: number;
+   /** Time window in milliseconds */
+   timeWindow: number;
+   /** Custom key prefix for Redis */
+   keyPrefix?: string;
+   /** Skip rate limiting for certain conditions */
+   skip?: (request: FastifyRequest) =&gt; boolean;
+   /** Custom identifier extraction (defaults to apiKeySource or IP) */
+   keyGenerator?: (request: FastifyRequest) =&gt; string;
+ }
+ 
+ interface RateLimitInfo {
+   /** Total requests allowed */
+   limit: number;
+   /** Remaining requests in current window */
+   remaining: number;
+   /** Timestamp when the rate limit resets (in seconds) */
+   reset: number;
+   /** Number of seconds until reset */
+   retryAfter?: number;
+ }
+ 
+ // =============================================================================
+ // Constants
+ // =============================================================================
+ 
+ const RATE_LIMIT_PREFIX = 'ratelimit';
+ const LUA_SLIDING_WINDOW = &#96;
+ local key = KEYS[1]
+ local now = tonumber(ARGV[1])
+ local window = tonumber(ARGV[2])
+ local max = tonumber(ARGV[3])
+ local windowStart = now - window
+ 
+ -- Remove old entries outside the window
+ redis.call('ZREMRANGEBYSCORE', key, '-inf', windowStart)
+ 
+ -- Count current requests in window
+ local count = redis.call('ZCARD', key)
+ 
+ if count &lt; max then
+   -- Add current request timestamp
+   redis.call('ZADD', key, now, now .. '-' .. math.random())
+   -- Set expiry on the key
+   redis.call('PEXPIRE', key, window)
+   return {count + 1, 0}
+ else
+   -- Rate limited - return oldest entry time for retry calculation
+   local oldest = redis.call('ZRANGE', key, 0, 0, 'WITHSCORES')
+   local retryAfter = 0
+   if #oldest &gt; 0 then
+     retryAfter = math.ceil((tonumber(oldest[2]) + window - now) / 1000)
+   end
+   return {count, retryAfter}
+ end
+ &#96;;
+ 
+ // =============================================================================
+ // Helper Functions
+ // =============================================================================
+ 
+ /**
+  * Get the rate limit identifier for a request.
+  * Priority: apiKeySource &gt; X-Forwarded-For &gt; IP address
+  */
+ function getIdentifier(request: FastifyRequest): string {
+   // Use API key source if authenticated
+   if (request.apiKeySource) {
+     return &#96;source:${request.apiKeySource}&#96;;
+   }
+ 
+   // Fall back to IP address
+   const forwardedFor = request.headers['x-forwarded-for'];
+   const ip = forwardedFor
+     ? (Array.isArray(forwardedFor) ? forwardedFor[0] : forwardedFor.split(',')[0].trim())
+     : request.ip;
+ 
+   return &#96;ip:${ip}&#96;;
+ }
+ 
+ /**
+  * Build the Redis key for rate limiting.
+  */
+ function buildKey(prefix: string, identifier: string): string {
+   return &#96;${prefix}:${identifier}&#96;;
+ }
+ 
+ // =============================================================================
+ // Rate Limit Middleware Factory
+ // =============================================================================
+ 
+ /**
+  * Creates a rate limiting middleware with configurable options.
+  * Uses Redis with sliding window algorithm for distributed rate limiting.
+  *
+  * @example
+  * // Basic usage with defaults from config
+  * fastify.addHook('preHandler', createRateLimiter());
+  *
+  * @example
+  * // Custom limits for specific routes
+  * fastify.addHook('preHandler', createRateLimiter({
+  *   max: 10,
+  *   timeWindow: 60000, // 1 minute
+  *   keyPrefix: 'api:heavy'
+  * }));
+  */
+ export function createRateLimiter(options: Partial&lt;RateLimitConfig&gt; = {}) {
+   const {
+     max = config.rateLimit.max,
+     timeWindow = config.rateLimit.timeWindow,
+     keyPrefix = RATE_LIMIT_PREFIX,
+     skip,
+     keyGenerator = getIdentifier
+   } = options;
+ 
+   return async function rateLimitMiddleware(
+     request: FastifyRequest,
+     reply: FastifyReply
+   ): Promise&lt;void&gt; {
+     // Skip rate limiting if configured
+     if (skip &amp;&amp; skip(request)) {
+       return;
+     }
+ 
+     const redis = getRedisConnection();
+     const identifier = keyGenerator(request);
+     const key = buildKey(keyPrefix, identifier);
+     const now = Date.now();
+ 
+     try {
+       // Execute Lua script for atomic rate limiting
+       const result = await redis.eval(
+         LUA_SLIDING_WINDOW,
+         1,
+         key,
+         now.toString(),
+         timeWindow.toString(),
+         max.toString()
+       ) as [number, number];
+ 
+       const [count, retryAfter] = result;
+       const remaining = Math.max(0, max - count);
+       const resetTime = Math.ceil((now + timeWindow) / 1000);
+ 
+       // Set rate limit headers
+       reply.header('X-RateLimit-Limit', max.toString());
+       reply.header('X-RateLimit-Remaining', remaining.toString());
+       reply.header('X-RateLimit-Reset', resetTime.toString());
+ 
+       // Check if rate limited
+       if (count &gt; max) {
+         reply.header('Retry-After', retryAfter.toString());
+ 
+         request.log.warn({
+           identifier,
+           count,
+           max,
+           retryAfter
+         }, 'Rate limit exceeded');
+ 
+         throw new RateLimitError(retryAfter);
+       }
+ 
+       request.log.debug({
+         identifier,
+         remaining,
+         max
+       }, 'Rate limit check passed');
+     } catch (error) {
+       // Re-throw rate limit errors
+       if (error instanceof RateLimitError) {
+         throw error;
+       }
+ 
+       // Log Redis errors but don't block the request
+       request.log.error({
+         err: error,
+         identifier
+       }, 'Rate limit check failed, allowing request');
+ 
+       // In case of Redis failure, allow the request through
+       // This prevents rate limiting from blocking all traffic if Redis is down
+     }
+   };
+ }
+ 
+ // =============================================================================
+ // Pre-configured Rate Limiters
+ // =============================================================================
+ 
+ /**
+  * Default rate limiter using global configuration.
+  */
+ export const defaultRateLimiter = createRateLimiter();
+ 
+ /**
+  * Strict rate limiter for sensitive endpoints (e.g., auth, bulk operations).
+  * 10 requests per minute.
+  */
+ export const strictRateLimiter = createRateLimiter({
+   max: 10,
+   timeWindow: 60000,
+   keyPrefix: &#96;${RATE_LIMIT_PREFIX}:strict&#96;
+ });
+ 
+ /**
+  * Relaxed rate limiter for read-heavy endpoints.
+  * 500 requests per minute.
+  */
+ export const relaxedRateLimiter = createRateLimiter({
+   max: 500,
+   timeWindow: 60000,
+   keyPrefix: &#96;${RATE_LIMIT_PREFIX}:relaxed&#96;
+ });
+ 
+ /**
+  * Webhook rate limiter per source.
+  * 1000 requests per minute per source.
+  */
+ export const webhookRateLimiter = createRateLimiter({
+   max: 1000,
+   timeWindow: 60000,
+   keyPrefix: &#96;${RATE_LIMIT_PREFIX}:webhook&#96;
+ });
+ 
+ // =============================================================================
+ // Utility Functions
+ // =============================================================================
+ 
+ /**
+  * Get current rate limit info for an identifier without incrementing.
+  * Useful for displaying rate limit status.
+  */
+ export async function getRateLimitInfo(
+   identifier: string,
+   options: Partial&lt;RateLimitConfig&gt; = {}
+ ): Promise&lt;RateLimitInfo&gt; {
+   const {
+     max = config.rateLimit.max,
+     timeWindow = config.rateLimit.timeWindow,
+     keyPrefix = RATE_LIMIT_PREFIX
+   } = options;
+ 
+   const redis = getRedisConnection();
+   const key = buildKey(keyPrefix, identifier);
+   const now = Date.now();
+   const windowStart = now - timeWindow;
+ 
+   // Remove old entries and count
+   await redis.zremrangebyscore(key, '-inf', windowStart);
+   const count = await redis.zcard(key);
+ 
+   const remaining = Math.max(0, max - count);
+   const reset = Math.ceil((now + timeWindow) / 1000);
+ 
+   return {
+     limit: max,
+     remaining,
+     reset
+   };
+ }
+ 
+ /**
+  * Reset rate limit for a specific identifier.
+  * Useful for administrative purposes.
+  */
+ export async function resetRateLimit(
+   identifier: string,
+   keyPrefix: string = RATE_LIMIT_PREFIX
+ ): Promise&lt;void&gt; {
+   const redis = getRedisConnection();
+   const key = buildKey(keyPrefix, identifier);
+   await redis.del(key);
+ }
+ 
+ /**
+  * Reset all rate limits (use with caution).
+  */
+ export async function resetAllRateLimits(
+   keyPrefix: string = RATE_LIMIT_PREFIX
+ ): Promise&lt;number&gt; {
+   const redis = getRedisConnection();
+   const pattern = &#96;${keyPrefix}:*&#96;;
+   
+   let cursor = '0';
+   let deletedCount = 0;
+ 
+   do {
+     const [newCursor, keys] = await redis.scan(cursor, 'MATCH', pattern, 'COUNT', 100);
+     cursor = newCursor;
+ 
+     if (keys.length &gt; 0) {
+       await redis.del(...keys);
+       deletedCount += keys.length;
+     }
+   } while (cursor !== '0');
+ 
+   return deletedCount;
+ }
+ 
+ // =============================================================================
+ // Default Export
+ // =============================================================================
+ 
+ export default createRateLimiter;
+ 
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Jetzt muss ich die Lints überprüfen und sicherstellen, dass keine Fehler vorhanden sind.</details></think>

---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** • Read lints for 1 file</summary>
      
Lint paths:

- `e:\dname\crm_dna-me\src\api\middleware\rateLimit.ts`

Lint results


**No lint errors found**
</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Die Rate-Limiting Middleware ist fertig implementiert und hat keine Linter-Fehler. Jetzt markiere ich den Task als abgeschlossen.</details></think>

---

Die Rate-Limiting Middleware wurde erfolgreich erstellt. Jetzt markiere ich den Task als abgeschlossen:

---

<tool-use data-tool-type="task" data-tool-name="todo_write">
<details><summary>Tool use: **todo_write** • Todo List</summary>

- [x] Erstelle src/api/middleware/rateLimit.ts

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Ausgezeichnet! Die Aufgabe ist erledigt. Lass mich eine Zusammenfassung der implementierten Funktionalität geben.</details></think>

---

Fertig! Die Rate-Limiting Middleware wurde erfolgreich implementiert.

## Zusammenfassung

Die Datei `src/api/middleware/rateLimit.ts` bietet folgende Funktionen:

### Hauptfunktionen

1. **Per-Source Rate-Limiting** - Begrenzt Anfragen basierend auf:
   - `apiKeySource` (wenn über API-Key authentifiziert)
   - IP-Adresse als Fallback

2. **Redis-basierter Sliding Window Algorithmus** - Verwendet ein Lua-Script für atomare, verteilte Rate-Limiting-Operationen

3. **Standard HTTP-Header**:
   - `X-RateLimit-Limit` - Maximale Anfragen
   - `X-RateLimit-Remaining` - Verbleibende Anfragen
   - `X-RateLimit-Reset` - Reset-Zeitstempel
   - `Retry-After` - Wartezeit bei Überschreitung

### Vorkonfigurierte Limiter

| Limiter | Limit | Zeitfenster | Anwendungsfall |
|---------|-------|-------------|----------------|
| `defaultRateLimiter` | 100/min | 60s | Standard-API-Endpunkte |
| `strictRateLimiter` | 10/min | 60s | Sensitive Endpunkte (Auth, Bulk) |
| `relaxedRateLimiter` | 500/min | 60s | Read-heavy Endpunkte |
| `webhookRateLimiter` | 1000/min | 60s | Webhook-Eingänge |

### Verwendungsbeispiele

```typescript
import { createRateLimiter, defaultRateLimiter, strictRateLimiter } from './middleware/rateLimit.js';

// Standard-Limiter für alle Routes
fastify.addHook('preHandler', defaultRateLimiter);

// Strikte Limits für spezifische Routes
fastify.post('/api/v1/leads/bulk', { preHandler: strictRateLimiter }, handler);

// Benutzerdefinierter Limiter
const customLimiter = createRateLimiter({
  max: 50,
  timeWindow: 30000,
  keyPrefix: 'custom'
});
```

---

